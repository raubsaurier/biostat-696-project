# fit an exponential semi-variogram
exp.variog <- fit.variogram(emp.variog,vgm(psill=max(emp.variog$gamma)*0.9,  model="Exp",
range=max(emp.variog$dist)/2, nugget = mean(emp.variog$gamma)/4),fit.method=2)
exp.variog
print(plot(emp.variog,exp.variog, main="Exponential Semi-Variogram"))
attr(exp.variog, "SSErr")
print(plot(emp.variog,sph.variog , main="Spherical Semi-Variogram"))
# fit an exponential semi-variogram
exp.variog <- fit.variogram(emp.variog,vgm(psill=max(emp.variog$gamma)*0.8,  model="Exp",
range=max(emp.variog$dist)/2, nugget = mean(emp.variog$gamma)/4),fit.method=2)
exp.variog
# make a plot of the empirical semi-variogram with the exponential semi-variogram overlayed
print(plot(emp.variog,exp.variog, main="Exponential Semi-Variogram"))
attr(exp.variog, "SSErr")
# fit an exponential semi-variogram
exp.variog <- fit.variogram(emp.variog,vgm(psill=max(emp.variog$gamma)*0.6,  model="Exp",
range=max(emp.variog$dist)/2, nugget = mean(emp.variog$gamma)/4),fit.method=2)
exp.variog
# make a plot of the empirical semi-variogram with the exponential semi-variogram overlayed
print(plot(emp.variog,exp.variog, main="Exponential Semi-Variogram"))
attr(exp.variog, "SSErr")
## specify the initial values for the parameters
beta.init <- loglinear_model$coefficients# use the estimates of beta from our loglinear GLM model
sigma2.init <- exp.variog$psill[2]
phi.init <- 1/exp.variog$range[2] # range
tau2.init <- exp.variog$psill[1]  # if we want a nugget effect
## try a spherical semi variogram w/ nugget effect
sph.variog <- fit.variogram(emp.variog, vgm(psill=max(emp.variog$gamma)*0.6, model = "Sph",
range=max(emp.variog$dist)/2, nugget = mean(emp.variog$gamma)/4))
sph.variog
# make a plot of the empirical semi-variogram with the spherical semi-variogram overlayed
print(plot(emp.variog,sph.variog , main="Spherical Semi-Variogram"))
attr(sph.variog, "SSErr")
## set up the model
n.batch <- 500
batch.length <- 100
n.samples = n.batch*batch.length
burn.in <- 0.5*n.samples
# for reproducibility
set.seed(20190301)
## fit a Bayesian GLM
asthmaBayes <- spGLM(asthma_count ~obesity_rate_2016 + pct_daily_smokers + meanAQI.Ozone + meanAQI.Other + pct_black
, weights = total_child_pop, family="poisson",
coords=coords,starting=list("phi"=phi.init,"sigma.sq"=sigma2.init, "tau.sq"=tau2.init,"beta"=beta.init, "w"=0),
tuning=list("phi"=0.00001, "sigma.sq"=0.00001, "tau.sq"=0.0001, beta=c(rep(0.00001, length(beta.init))), "w"=0.00001), #tried several different values of the tuning to make the trace plots look nicer
priors=list("phi.Unif"=c(0.001, 0.1), "sigma.sq.IG"=c(2, 1),
"tau.sq.IG"=c(2, 1),"beta.Flat"), cov.model="exponential",n.samples=n.samples, verbose=TRUE, n.report=0.2*n.samples)
### diagnostics for convergence
## effective sample size for each variable:
samps <- mcmc.list(asthmaBayes$p.beta.theta.samples)
effectiveSize(samps)
asthma_model <- asthma_with_coords[,c("state","asthma_count", "obesity_rate_2016",
"pct_daily_smokers", "meanAQI.Ozone", "meanAQI.Other", "pct_black", "lat", "long", "total_population")]
asthma_subset <- asthma_model[!is.na(asthma_model$asthma_count)]
coords <- as.matrix(cbind(asthma_subset$lat, asthma_subset$long))
## get the covariates
asthma_count <- asthma_subset$asthma_count
obesity_rate_2016 <- asthma_subset$obesity_rate_2016
pct_daily_smokers <- asthma_subset$pct_daily_smokers
meanAQI.Ozone <- asthma_subset$meanAQI.Ozone
meanAQI.Other <- asthma_subset$meanAQI.Other
pct_black <- asthma_subset$pct_black
total_child_pop <- asthma_subset$total_population
## set up the model
n.batch <- 500
batch.length <- 100
n.samples = n.batch*batch.length
burn.in <- 0.5*n.samples
# for reproducibility
set.seed(20190301)
## fit a Bayesian GLM
asthmaBayes <- spGLM(asthma_count ~obesity_rate_2016 + pct_daily_smokers + meanAQI.Ozone + meanAQI.Other + pct_black
, weights = total_child_pop, family="poisson",
coords=coords,starting=list("phi"=phi.init,"sigma.sq"=sigma2.init, "tau.sq"=tau2.init,"beta"=beta.init, "w"=0),
tuning=list("phi"=0.00001, "sigma.sq"=0.00001, "tau.sq"=0.0001, beta=c(rep(0.00001, length(beta.init))), "w"=0.00001), #tried several different values of the tuning to make the trace plots look nicer
priors=list("phi.Unif"=c(0.001, 0.1), "sigma.sq.IG"=c(2, 1),
"tau.sq.IG"=c(2, 1),"beta.Flat"), cov.model="exponential",n.samples=n.samples, verbose=TRUE, n.report=0.2*n.samples)
### diagnostics for convergence
## effective sample size for each variable:
samps <- mcmc.list(asthmaBayes$p.beta.theta.samples)
effectiveSize(samps)
## set up the model
n.batch <- 500
batch.length <- 100
n.samples = n.batch*batch.length
burn.in <- 0.5*n.samples
# for reproducibility
set.seed(20190301)
## fit a Bayesian GLM
asthmaBayes <- spGLM(asthma_count ~obesity_rate_2016 + pct_daily_smokers + meanAQI.Ozone + meanAQI.Other
, weights = total_child_pop, family="poisson",
coords=coords,starting=list("phi"=phi.init,"sigma.sq"=sigma2.init, "tau.sq"=tau2.init,"beta"=beta.init, "w"=0),
tuning=list("phi"=0.00001, "sigma.sq"=0.00001, "tau.sq"=0.0001, beta=c(rep(0.00001, length(beta.init))), "w"=0.00001), #tried several different values of the tuning to make the trace plots look nicer
priors=list("phi.Unif"=c(0.001, 0.1), "sigma.sq.IG"=c(2, 1),
"tau.sq.IG"=c(2, 1),"beta.Flat"), cov.model="exponential",n.samples=n.samples, verbose=TRUE, n.report=0.2*n.samples)
### diagnostics for convergence
## effective sample size for each variable:
samps <- mcmc.list(asthmaBayes$p.beta.theta.samples)
effectiveSize(samps)
## set up the model
n.batch <- 500
batch.length <- 100
n.samples = n.batch*batch.length
burn.in <- 0.5*n.samples
# for reproducibility
set.seed(20190301)
## fit a Bayesian GLM
asthmaBayes <- spGLM(asthma_count ~obesity_rate_2016 + pct_daily_smokers + meanAQI.Ozone + meanAQI.Other + pct_black
, weights = total_child_pop, family="poisson",
coords=coords,starting=list("phi"=phi.init,"sigma.sq"=sigma2.init, "tau.sq"=tau2.init,"beta"=beta.init, "w"=0),
tuning=list("phi"=0.00001, "sigma.sq"=0.00001, "tau.sq"=0.0001, beta=c(rep(0.00001, length(beta.init))), "w"=0.00001), #tried several different values of the tuning to make the trace plots look nicer
priors=list("phi.Unif"=c(0.001, 0.1), "sigma.sq.IG"=c(2, 1),
"tau.sq.IG"=c(2, 1),"beta.Flat"), cov.model="exponential",n.samples=n.samples, verbose=TRUE, n.report=0.2*n.samples)
### diagnostics for convergence
## effective sample size for each variable:
samps <- mcmc.list(asthmaBayes$p.beta.theta.samples)
effectiveSize(samps)
beta.init
## fit a Bayesian GLM
asthmaBayes <- spGLM(asthma_count ~obesity_rate_2016 + pct_daily_smokers + meanAQI.Ozone
, weights = total_child_pop, family="poisson",
coords=coords,starting=list("phi"=phi.init,"sigma.sq"=sigma2.init, "tau.sq"=tau2.init,"beta"=beta.init, "w"=0),
tuning=list("phi"=0.00001, "sigma.sq"=0.00001, "tau.sq"=0.0001, beta=c(rep(0.00001, length(beta.init))), "w"=0.00001), #tried several different values of the tuning to make the trace plots look nicer
priors=list("phi.Unif"=c(0.001, 0.1), "sigma.sq.IG"=c(2, 1),
"tau.sq.IG"=c(2, 1),"beta.Flat"), cov.model="exponential",n.samples=n.samples, verbose=TRUE, n.report=0.2*n.samples)
## fit a Bayesian GLM
asthmaBayes <- spGLM(asthma_count ~obesity_rate_2016 + pct_daily_smokers + meanAQI.Ozone
, weights = total_child_pop, family="poisson",
coords=coords,starting=list("phi"=phi.init,"sigma.sq"=sigma2.init, "tau.sq"=tau2.init,"beta"=beta.init, "w"=0),
tuning=list("phi"=0.00001, "sigma.sq"=0.00001, "tau.sq"=0.0001, beta=c(rep(0.00001, length(beta.init))), "w"=0.00001), #tried several different values of the tuning to make the trace plots look nicer
priors=list("phi.Unif"=c(0.01, 0.1), "sigma.sq.IG"=c(2, 1),
"tau.sq.IG"=c(2, 1),"beta.Flat"), cov.model="exponential",n.samples=n.samples, verbose=TRUE, n.report=0.2*n.samples)
## fit a Bayesian GLM
asthmaBayes <- spGLM(asthma_count ~obesity_rate_2016 + pct_daily_smokers + meanAQI.Ozone
, weights = total_child_pop, family="poisson",
coords=coords,starting=list("phi"=phi.init,"sigma.sq"=sigma2.init, "tau.sq"=tau2.init,"beta"=beta.init, "w"=0),
tuning=list("phi"=0.00001, "sigma.sq"=0.00001, "tau.sq"=0.0001, beta=c(rep(0.000001, length(beta.init))), "w"=0.00001), #tried several different values of the tuning to make the trace plots look nicer
priors=list("phi.Unif"=c(0.01, 0.1), "sigma.sq.IG"=c(100, 1),
"tau.sq.IG"=c(100, 1),"beta.Flat"), cov.model="exponential",n.samples=n.samples, verbose=TRUE, n.report=0.2*n.samples)
## fit a Bayesian GLM
asthmaBayes <- spGLM(asthma_count ~obesity_rate_2016 + pct_daily_smokers + meanAQI.Ozone
, weights = total_child_pop, family="poisson",
coords=coords,starting=list("phi"=phi.init,"sigma.sq"=sigma2.init, "tau.sq"=tau2.init,"beta"=beta.init, "w"=0),
tuning=list("phi"=0.00001, "sigma.sq"=0.00001, "tau.sq"=0.0001, beta=c(rep(0.000001, length(beta.init))), "w"=0.00001), #tried several different values of the tuning to make the trace plots look nicer
priors=list("phi.Unif"=c(0.01, 0.1), "sigma.sq.IG"=c(100, 0.1),
"tau.sq.IG"=c(100, 0.1),"beta.Flat"), cov.model="exponential",n.samples=n.samples, verbose=TRUE, n.report=0.2*n.samples)
## fit a Bayesian GLM
asthmaBayes <- spGLM(asthma_count ~obesity_rate_2016 + pct_daily_smokers + meanAQI.Ozone
, weights = total_child_pop, family="poisson",
coords=coords,starting=list("phi"=phi.init,"sigma.sq"=sigma2.init, "tau.sq"=tau2.init,"beta"=beta.init, "w"=0),
tuning=list("phi"=0.00001, "sigma.sq"=0.00001, "tau.sq"=0.000001, beta=c(rep(0.000001, length(beta.init))), "w"=0.00001), #tried several different values of the tuning to make the trace plots look nicer
priors=list("phi.Unif"=c(0.01, 0.1), "sigma.sq.IG"=c(100, 0.1),
"tau.sq.IG"=c(100, 0.1),"beta.Flat"), cov.model="exponential",n.samples=n.samples, verbose=TRUE, n.report=0.2*n.samples)
## effective sample size for each variable:
samps <- mcmc.list(asthmaBayes$p.beta.theta.samples)
effectiveSize(samps)
## we are looking to see if the mean of the chains for each variable has converged
heidel.diag(samps, eps=0.1, pvalue=0.05)
## Geweke diagnostic:
geweke.diag(samps, frac1=0.1, frac2=0.5)
## Trace plots of the parameters
par(mai=rep(0.5,4))
plot(asthmaBayes$p.beta.theta.samples)
## set up the model
n.batch <- 5000
batch.length <- 100
n.samples = n.batch*batch.length
burn.in <- 0.5*n.samples
# for reproducibility
set.seed(20190301)
## fit a Bayesian GLM
asthmaBayes <- spGLM(asthma_count ~obesity_rate_2016 + pct_daily_smokers + meanAQI.Ozone
, weights = total_child_pop, family="poisson",
coords=coords,starting=list("phi"=phi.init,"sigma.sq"=sigma2.init, "tau.sq"=tau2.init,"beta"=beta.init, "w"=0),
tuning=list("phi"=0.00001, "sigma.sq"=0.00001, "tau.sq"=0.000001, beta=c(rep(0.000001, length(beta.init))), "w"=0.00001), #tried several different values of the tuning to make the trace plots look nicer
priors=list("phi.Unif"=c(0.01, 0.1), "sigma.sq.IG"=c(100, 0.1),
"tau.sq.IG"=c(100, 0.1),"beta.Flat"), cov.model="exponential",n.samples=n.samples, verbose=TRUE, n.report=0.2*n.samples)
## effective sample size for each variable:
samps <- mcmc.list(asthmaBayes$p.beta.theta.samples)
effectiveSize(samps)
heidel.diag(samps, eps=0.1, pvalue=0.05)
## Geweke diagnostic:
geweke.diag(samps, frac1=0.1, frac2=0.5)
## Trace plots of the parameters
par(mai=rep(0.5,4))
plot(asthmaBayes$p.beta.theta.samples)
## set up the model
n.batch <- 500
batch.length <- 100
n.samples = n.batch*batch.length
burn.in <- 0.5*n.samples
# for reproducibility
set.seed(20190301)
## fit a Bayesian GLM
asthmaBayes <- spGLM(asthma_count ~obesity_rate_2016 + pct_daily_smokers + meanAQI.Ozone + meanAQI.Other + pct_black
, weights = total_child_pop, family="poisson",
coords=coords,starting=list("phi"=phi.init,"sigma.sq"=sigma2.init, "tau.sq"=tau2.init,"beta"=beta.init, "w"=0),
tuning=list("phi"=0.00001, "sigma.sq"=0.00001, "tau.sq"=0.0001, beta=c(rep(0.00001, length(beta.init))), "w"=0.00001), #tried several different values of the tuning to make the trace plots look nicer
priors=list("phi.Unif"=c(0.001, 0.1), "sigma.sq.IG"=c(2, 1),
"tau.sq.IG"=c(2, 1),"beta.Flat"), cov.model="exponential",n.samples=n.samples, verbose=TRUE, n.report=0.2*n.samples)
### diagnostics for convergence
## effective sample size for each variable:
samps <- mcmc.list(asthmaBayes$p.beta.theta.samples)
effectiveSize(samps)
## we are looking to see if the mean of the chains for each variable has converged
heidel.diag(samps, eps=0.1, pvalue=0.05)
## Geweke diagnostic:
geweke.diag(samps, frac1=0.1, frac2=0.5)
## set up the model
n.batch <- 500
batch.length <- 100
n.samples = n.batch*batch.length
burn.in <- 0.5*n.samples
## set up the model
n.batch <- 500
batch.length <- 500
n.samples = n.batch*batch.length
burn.in <- 0.5*n.samples
## set up the model
n.batch <- 500
batch.length <- 100
n.samples = n.batch*batch.length
burn.in <- 0.5*n.samples
# for reproducibility
set.seed(20190301)
## fit a Bayesian GLM
asthmaBayes <- spGLM(asthma_count ~obesity_rate_2016 + pct_daily_smokers + meanAQI.Ozone + meanAQI.Other + pct_black
, weights = total_child_pop, family="poisson",
coords=coords,starting=list("phi"=phi.init,"sigma.sq"=sigma2.init, "tau.sq"=tau2.init,"beta"=beta.init, "w"=0),
tuning=list("phi"=0.00001, "sigma.sq"=0.00001, "tau.sq"=0.0001, beta=c(rep(0.00001, length(beta.init))), "w"=0.00001), #tried several different values of the tuning to make the trace plots look nicer
priors=list("phi.Unif"=c(0.001, 0.1), "sigma.sq.IG"=c(2, 1),
"tau.sq.IG"=c(2, 1),"beta.Flat"), cov.model="exponential",n.samples=n.samples, verbose=TRUE, n.report=0.2*n.samples)
## set up the model
n.batch <- 500
batch.length <- 500
n.samples = n.batch*batch.length
burn.in <- 0.5*n.samples
## fit a Bayesian GLM
asthmaBayes <- spGLM(asthma_count ~obesity_rate_2016 + pct_daily_smokers + meanAQI.Ozone
, weights = total_child_pop, family="poisson",
coords=coords,starting=list("phi"=phi.init,"sigma.sq"=sigma2.init, "tau.sq"=tau2.init,"beta"=beta.init, "w"=0),
tuning=list("phi"=0.00001, "sigma.sq"=0.00001, "tau.sq"=0.000001, beta=c(rep(0.000001, length(beta.init))), "w"=0.00001), #tried several different values of the tuning to make the trace plots look nicer
priors=list("phi.Unif"=c(0.01, 0.1), "sigma.sq.IG"=c(100, 0.1),
"tau.sq.IG"=c(100, 0.1),"beta.Flat"), cov.model="exponential",n.samples=n.samples, verbose=TRUE, n.report=0.2*n.samples)
asthma2016 <- data.table(read.csv("2016 Asthma Prevalence Complete_allStates_totalPop.csv"))
## we notice right away that some states are missing from the 2016 CDC prevalence estimates
setnames(asthma2016, c("Location", "total_count", "total_population"), c("state", "asthma_count", "total_child_pop"))
## get fips:
asthma2016$fips <- fips(asthma2016$state)
plot_usmap(data =asthma2016, values = "asthma_count", lines = "black") +
scale_fill_gradientn(colours=blue2red(10), name="Asthma Count") +
theme(legend.position = "right") +
labs(title="2016 Child Asthma by State")
setwd("~/repos/biostat-696-project")
asthma2016 <- data.table(read.csv("2016 Asthma Prevalence Complete.csv"))
setnames(asthma2016, c("Location", "total_count", "total_population"), c("state", "asthma_count", "total_child_pop"))
## get fips:
asthma2016$fips <- fips(asthma2016$state)
plot_usmap(data =asthma2016, values = "asthma_count", lines = "black") +
scale_fill_gradientn(colours=blue2red(10), name="Asthma Count") +
theme(legend.position = "right") +
labs(title="2016 Child Asthma by State")
View(asthma2016)
setnames(asthma2016, c("Location", "total_count", "total_population"), c("state", "asthma_count", "total_child_pop"))
asthma2016$asthma_count = as.numeric(gsub(",", "", asthma2016$asthma_count, fixed = TRUE))
## get fips:
asthma2016$fips <- fips(asthma2016$state)
plot_usmap(data =asthma2016, values = "asthma_count", lines = "black") +
scale_fill_gradientn(colours=blue2red(10), name="Asthma Count") +
theme(legend.position = "right") +
labs(title="2016 Child Asthma by State")
plot_usmap(data =asthma2016, values = "asthma_count", lines = "black", labels = TRUE) +
scale_fill_gradientn(colours=blue2red(10), name="Asthma Count") +
theme(legend.position = "right") +
labs(title="2016 Child Asthma by State")
## load in 2016 air quality data
airData2016 <- data.table(read.csv("daily_aqi_by_county_2016.csv"))
## extract month and year from the data
airData2016$Date <- lubridate::ymd(airData2016$Date)
airData2016$year <- lubridate::year(airData2016$Date)
## we will exclude Alaska and Hawaii from our analysis
airData2016 <- airData2016[!State.Name%in%c("National", "Alaska", "Hawaii")]
aggregatedAirData <- airData2016[,list(meanAQI=mean(na.omit(AQI))), by=c("State.Name", "Defining.Parameter","year")]
## get the FIPS for each state (used for plotting)
aggregatedAirData$fips <- fips(aggregatedAirData$State.Name)
## use log scale since California has some very high ozone values
aggregatedAirData$log_mean_AQI <- log(aggregatedAirData$meanAQI)
pollute_types <- unique(aggregatedAirData$Defining.Parameter)
pollute_types
plot_list <- list()
## plot the average AQI for each type of pollutant  on a state level
for (k in 1:length(pollute_types)){
graphData <- aggregatedAirData[Defining.Parameter==pollute_types[k]]
plot_list[[k]] <- plot_usmap(data =graphData, values = "log_mean_AQI", lines = "black") +
scale_fill_gradientn(colours=blue2red(5), name="Log Mean AQI") +
theme(legend.position = "right") +
labs(title=paste0("2016 Air Quality by State for ", pollute_types[k]))
}
plot_list[[2]]
plot_list[[3]]
plot_list[[5]]
plot_list[[4]]
plot_list[[6]]
plot_list[[1]]
?S.CARleroux
54+18
36-54
72/18
ln(-4)
log(-4)
54-36
ln(2)
log(2)
36-27
18/4
-81/(-4.5)
54/4
81/13.5
sqrt(7)
log(2)/sqrt(7)
sqrt(12)8log(2)^2
sqrt(12)*log(2)^2
sqrT(12)
sqrt(12)
log(2)
3.464102*xv
3.464102*0.6931472
## load in 2016 air quality data
airData2016 <- data.table(read.csv("daily_aqi_by_county_2016.csv"))
## extract month and year from the data
airData2016$Date <- lubridate::ymd(airData2016$Date)
airData2016$year <- lubridate::year(airData2016$Date)
## we will exclude Alaska and Hawaii from our analysis
airData2016 <- airData2016[!State.Name%in%c("National", "Alaska", "Hawaii")]
aggregatedAirData <- airData2016[,list(meanAQI=mean(na.omit(AQI))), by=c("State.Name", "Defining.Parameter","year")]
## get the FIPS for each state (used for plotting)
aggregatedAirData$fips <- fips(aggregatedAirData$State.Name)
## use log scale since California has some very high ozone values
aggregatedAirData$log_mean_AQI <- log(aggregatedAirData$meanAQI)
pollute_types <- unique(aggregatedAirData$Defining.Parameter)
plot_list <- list()
## plot the average AQI for each type of pollutant  on a state level
for (k in 1:length(pollute_types)){
graphData <- aggregatedAirData[Defining.Parameter==pollute_types[k]]
plot_list[[k]] <- plot_usmap(data =graphData, values = "log_mean_AQI", lines = "black") +
scale_fill_gradientn(colours=blue2red(5), name="Log Mean AQI") +
theme(legend.position = "right") +
labs(title=paste0("2016 Air Quality by State for ", pollute_types[k]))
}
## it appears that we are missing data for some of the pollutants (e.g. Nebraska does not have data for NO2)
## however, for ozone, we have data for all 50 states
## also, it has been established that asthma can be triggered by ozone, so moving forward, we will proceed with ozone only analysis
#### 4/13/2019 update: create a variable that indicates Ozone vs. other type of pollution in order to avoid confounding in the model
### 4/17 - include PM2 to include pollen by proxy
get_pollution_type <- function(pollution){
x <- "Other"
if(pollution=="Ozone"){
x <- "Ozone"
} else if(pollution=="PM2.5"){
x <- "PM2.5"
} else {
x <- x
}
return(x)
}
aggregatedAirData$pollution_type <- mapply(get_pollution_type, aggregatedAirData$Defining.Parameter)
aggregatedAirData <- aggregatedAirData[,c("year", "fips", "pollution_type", "meanAQI")]
aggregatedAirData <- aggregatedAirData[,list(meanAQI=sum(na.omit(meanAQI))), by=c("year", "fips", "pollution_type")]
reshapedData <- reshape(aggregatedAirData, idvar = c("year", "fips"), timevar = "pollution_type",
direction="wide")
View(reshapedData)
View(aggregatedAirData)
aggregatedAirData <- airData2016[,list(meanAQI=mean(na.omit(AQI))), by=c("State.Name", "Defining.Parameter","year")]
## get the FIPS for each state (used for plotting)
aggregatedAirData$fips <- fips(aggregatedAirData$State.Name)
## use log scale since California has some very high ozone values
aggregatedAirData$log_mean_AQI <- log(aggregatedAirData$meanAQI)
aggregatedAirData$pollution_type <- mapply(get_pollution_type, aggregatedAirData$Defining.Parameter)
aggregatedAirData <- aggregatedAirData[,c("year", "fips", "pollution_type", "meanAQI", "State.Name")]
aggregatedAirData <- aggregatedAirData[,list(meanAQI=sum(na.omit(meanAQI))), by=c("State.Name","year", "fips", "pollution_type")]
reshapedData <- reshape(aggregatedAirData, idvar = c("year", "fips"), timevar = "pollution_type",
direction="wide")
View(reshapedData)
reshapedData <- reshape(aggregatedAirData, idvar = c("year", "State.Name","fips"), timevar = "pollution_type",
direction="wide")
View(reshapedData)
pollute_types <- unique(aggregatedAirData$Defining.Parameter)
plot_list <- list()
## plot the average AQI for each type of pollutant  on a state level
for (k in 1:length(pollute_types)){
graphData <- aggregatedAirData[Defining.Parameter==pollute_types[k]]
plot_list[[k]] <- plot_usmap(data =graphData, values = "log_mean_AQI", lines = "black") +
scale_fill_gradientn(colours=blue2red(5), name="Log Mean AQI") +
theme(legend.position = "right") +
labs(title=paste0("2016 Air Quality by State for ", pollute_types[k]))
}
## we will exclude Alaska and Hawaii from our analysis
airData2016 <- airData2016[!State.Name%in%c("National", "Alaska", "Hawaii")]
aggregatedAirData <- airData2016[,list(meanAQI=mean(na.omit(AQI))), by=c("State.Name", "Defining.Parameter","year")]
## get the FIPS for each state (used for plotting)
aggregatedAirData$fips <- fips(aggregatedAirData$State.Name)
## use log scale since California has some very high ozone values
aggregatedAirData$log_mean_AQI <- log(aggregatedAirData$meanAQI)
pollute_types <- unique(aggregatedAirData$Defining.Parameter)
plot_list <- list()
## plot the average AQI for each type of pollutant  on a state level
for (k in 1:length(pollute_types)){
graphData <- aggregatedAirData[Defining.Parameter==pollute_types[k]]
plot_list[[k]] <- plot_usmap(data =graphData, values = "log_mean_AQI", lines = "black") +
scale_fill_gradientn(colours=blue2red(5), name="Log Mean AQI") +
theme(legend.position = "right") +
labs(title=paste0("2016 Air Quality by State for ", pollute_types[k]))
}
plot_list[[1]]
plot_list[[2]]
smoking2016 <- data.table(read_excel("daily_smoking_adults_2016.xlsx"))
## this data is messy -> need to clean it
colnames(smoking2016) <- c("state", "pct_daily_smokers")
## only keep the continental US states
smoking2016 <-smoking2016[1:51,]
smoking2016 <- smoking2016[!state%in%c("National", "Alaska", "Hawaii")]
## make a visualization of this data
smoking2016$fips <- fips(smoking2016$state)
View(smoking2016)
obesity2016 <- data.table(read_xlsx("childhood_obesity_2016_2017.xlsx"))
obesity2016 <- obesity2016[!State%in%c("Alaska", "Hawaii")]
## make a visualization of this data
obesity2016$fips <- fips(obesity2016$State)
obesity2016$State <- NULL
View(obesity2016)
obesity2016 <- data.table(read_xlsx("childhood_obesity_2016_2017.xlsx"))
obesity2016 <- obesity2016[!State%in%c("Alaska", "Hawaii")]
## make a visualization of this data
obesity2016$fips <- fips(obesity2016$State)
View(obesity2016)
plot_usmap(data =obesity2016, values = "obesity_rate_2016", lines = "black") +
scale_fill_gradientn(colours=blue2red(10), name="Obesity Rate (in %)") +
theme(legend.position = "right") +
labs(title="2016 Child Obesity Rate by State")
## 2016 population demographic data for US states
demographicData <- data.table(read_xlsx("race_ethnicity_data.xlsx"))
colnames(demographicData) <- as.character(demographicData[1,])
demographicData <- demographicData[-1,]
#don't need this column, as it is empty anyway
demographicData$Footnotes <- NULL
## Research shows that African-American children have the highest prevalence of asthma
demographicData$pct_white <- as.numeric(demographicData$White)/as.numeric(demographicData$Total)
# montana doesn't have data on # of black residents
demographicData$pct_black <- as.numeric(demographicData$Black)/as.numeric(demographicData$Total)
setnames(demographicData, "Location", "state")
demographicData$fips <- fips(demographicData$state)
# drop Puerto Rico, and "National" data
demographicData <- demographicData[!is.na(fips)]
finalDemoData <- demographicData[,c("fips", "state", "pct_white", "pct_black")]
View(finalDemoData)
obesity2016$fips <- fips(obesity2016$State)
setnames(obesity2016, "State", "state")
demographicData <- demographicData[!is.na(fips)]
finalDemoData <- demographicData[,c("fips", "state", "pct_white", "pct_black")]
View(finalDemoData)
ozoneData <- copy(reshapedData)
totalData <- merge(obesity2016, smoking2016, by=c("fips", "state")
)
totalData <- merge(totalData, ozoneData, by=c("fips", "state"))
totalData <- merge(totalData, finalDemoData, by=c("fips", "state"))
setnames(reshapedData, "State.Name", "state")
ozoneData <- copy(reshapedData)
totalData <- merge(obesity2016, smoking2016, by=c("fips", "state"))
totalData <- merge(totalData, ozoneData, by=c("fips", "state"))
totalData <- merge(totalData, finalDemoData, by=c("fips", "state"))
View(totalData)
View(totalData)
## 2016 population demographic data for US states
demographicData <- data.table(read_xlsx("race_ethnicity_data.xlsx"))
colnames(demographicData) <- as.character(demographicData[1,])
demographicData <- demographicData[-1,]
#don't need this column, as it is empty anyway
demographicData$Footnotes <- NULL
## Research shows that African-American children have the highest prevalence of asthma
demographicData$pct_white <- as.numeric(demographicData$White)/as.numeric(demographicData$Total)
# montana doesn't have data on # of black residents
demographicData$pct_black <- as.numeric(demographicData$Black)/as.numeric(demographicData$Total)
setnames(demographicData, "Location", "state")
## use 2017 % of black residents for Montana since 2016 data was not available
demographicData[state=="Montana"]$pct_black <- 0.01
demographicData$fips <- fips(demographicData$state)
# drop Puerto Rico, and "National" data
demographicData <- demographicData[!is.na(fips)]
finalDemoData <- demographicData[,c("fips", "state", "pct_white", "pct_black")]
View(finalDemoData)
ozoneData <- copy(reshapedData)
totalData <- merge(obesity2016, smoking2016, by=c("fips", "state"))
totalData <- merge(totalData, ozoneData, by=c("fips", "state"))
totalData <- merge(totalData, finalDemoData, by=c("fips", "state"))
View(totalData)
corrVars <- corrData[,c("obesity_rate_2016", "pct_daily_smokers", "meanAQI.Ozone", "pct_black", "pct_white")]
cor(corrVars)
corrVars <- totalData[,c("obesity_rate_2016", "pct_daily_smokers", "meanAQI.Ozone", "pct_black", "pct_white")]
cor(corrVars)
asthma2016 <- data.table(read.csv("2016 Asthma Prevalence Complete.csv"))
## we notice right away that some states are missing from the 2016 CDC prevalence estimates
setnames(asthma2016, c("Location", "total_count", "total_population"), c("state", "asthma_count", "total_child_pop"))
asthma2016$asthma_count = as.numeric(gsub(",", "", asthma2016$asthma_count, fixed = TRUE))
## get fips:
asthma2016$fips <- fips(asthma2016$state)
plot_usmap(data =asthma2016, values = "asthma_count", lines = "black", labels = TRUE) +
scale_fill_gradientn(colours=blue2red(10), name="Asthma Count") +
theme(legend.position = "right") +
labs(title="2016 Child Asthma by State")
## Merge asthma data with covariates
asthma_data = merge(asthma2016, totalData, by = c("state","fips"), all.y=TRUE)
View(asthma_data)
